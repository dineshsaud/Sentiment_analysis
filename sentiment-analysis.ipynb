{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T06:03:12.136658Z",
     "iopub.status.busy": "2021-10-10T06:03:12.136371Z",
     "iopub.status.idle": "2021-10-10T06:03:16.274155Z",
     "shell.execute_reply": "2021-10-10T06:03:16.273314Z",
     "shell.execute_reply.started": "2021-10-10T06:03:12.136579Z"
    }
   },
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:30px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " Sentiment Analysis on Amazon fine foods reviews </h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1. Importing Necessary Pacakages</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:24.461293Z",
     "iopub.status.busy": "2021-10-10T14:30:24.459714Z",
     "iopub.status.idle": "2021-10-10T14:30:24.466019Z",
     "shell.execute_reply": "2021-10-10T14:30:24.465315Z",
     "shell.execute_reply.started": "2021-10-10T14:30:24.461248Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import pandas as  pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1.1. Numpy</h2>\n",
    "<br>\n",
    "\n",
    "Numpy stands for Numerical python , it is a library consisting of multidimensional array objects. and collection of routines (collection of repeated code ) for processing arrays.\n",
    "\n",
    "#### 1.1.1 Facilitate\n",
    "- mathematical and logical operations on arrays\n",
    "- Transform and shape manipulation of arrays (matrix , vector)\n",
    "- Operations for linear algebra and Random number generator functions\n",
    "<br>\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1.2. Pandas </h2>\n",
    "<br>\n",
    "\n",
    "\n",
    "It is an Library that is built on the top of numpy library. It is mostly used for data science and machine learning.\n",
    "\n",
    "#### 1.2.1 Facilitate\n",
    "\n",
    "- Data loading\n",
    "- Data cleansing\n",
    "- Data filling\n",
    "- Data normalization\n",
    "- many more\n",
    "\n",
    "#### 1.3. String\n",
    "The string module contains a number of functions to process standard Python strings,he module also contains a number of functions that convert strings to other types\n",
    "Â¶hiv testing lagankhel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:24.468283Z",
     "iopub.status.busy": "2021-10-10T14:30:24.467775Z",
     "iopub.status.idle": "2021-10-10T14:30:24.479391Z",
     "shell.execute_reply": "2021-10-10T14:30:24.478676Z",
     "shell.execute_reply.started": "2021-10-10T14:30:24.468248Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns \n",
    "import seaborn as sns \n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.express as px \n",
    "import plotly.graph_objs as go \n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1.3 Matplot lib </h2>\n",
    "<br>\n",
    "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "\n",
    "matplotlib. pyplot is a collection of functions that make matplotlib work like MATLAB. Each pyplot function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc. In matplotlib.\n",
    "\n",
    "### matplot lib inline\n",
    "\n",
    "We use the function %matplotlib inline to enable the inline plotting, where the plots/graphs will be displayed just below the cell where your plotting commands are written.\n",
    "<b>This means we don't have to call plt.show()</b> every time we create some plots.\n",
    "\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1.4 Seaborn </h2>\n",
    "Seaborn is a library for making statistical graphics in Python. It builds on top of matplotlib and integrates closely with pandas data structures.\n",
    "\n",
    "- explore and understand our data.\n",
    "- operate on data frames and arrays containing while datasets\n",
    "- perform the necessary semantic mapping and statistical aggregation to produce informative plots\n",
    "\n",
    "\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1.5 Plotly </h2>\n",
    "\n",
    "Plotly is a platform to create data visualization. it can be used in languages like python, R, js and juliya.\n",
    "\n",
    "### plotly.offline\n",
    "\n",
    "Normally we would have to use plotly online that is by creating an account on  https://plot.ly. When using online mode our plots will be saved in our plotly account. But what if we want to save our plots on our local machine. so we can do that by ****plotly.offline ****\n",
    "\n",
    "### plotly.express\n",
    "Plotly Express is a high-level wrapper for Plotly,This means we can do a lot of things with simpler syntax. After it is installed we can just simply import plotly.exoress and make interactive visualizations with Python.are\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:24.481185Z",
     "iopub.status.busy": "2021-10-10T14:30:24.480823Z",
     "iopub.status.idle": "2021-10-10T14:30:24.488849Z",
     "shell.execute_reply": "2021-10-10T14:30:24.488119Z",
     "shell.execute_reply.started": "2021-10-10T14:30:24.481148Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from wordcloud import WordCloud , STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "1.6 NLTK </h2>\n",
    "NLTK stands for Natural Language Toolkit. NLTK is a suite that contains libraries and programs for statical language processing. It is used to make machine understand text and speech to human.\n",
    "\n",
    "### stopwords\n",
    "stopwords are those words that does not add meaning to a sentence. They can be ignored and yet meaning of the sentence is unchanged.\n",
    "\n",
    "### PorterStemmer\n",
    "\n",
    "PorterStemmer is a package that lets us do stemming. Stemming is the process of reducing inflection of a word to its core. ex: paying -> pay , paid -> pay\n",
    "\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1.7 Word Cloud </h2>   \n",
    "word clouds are visualization technique for understanding and determining patterns and evolving trends in the word data.\n",
    "\n",
    "A bigger word in the word cloud represents that the word prominence is higher(i.e) the word is repeated more\n",
    "    \n",
    "    \n",
    "1. **corpus:**\n",
    "collection of written words. usually large and structured set of texts.\n",
    "\n",
    "2. **NLTK.corpus file:**\n",
    "It is a massive dump of all kinds of natural language datasets. Most of the part is in plain text file in this module. where as some part can be seen in XML format\n",
    "\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:24.492743Z",
     "iopub.status.busy": "2021-10-10T14:30:24.492545Z",
     "iopub.status.idle": "2021-10-10T14:30:24.499687Z",
     "shell.execute_reply": "2021-10-10T14:30:24.498951Z",
     "shell.execute_reply.started": "2021-10-10T14:30:24.492722Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import pickle  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 1.8 Word Vectorization </h2>\n",
    "\n",
    "In simple words it is the process of converting words into numbers.\n",
    "\n",
    "Word Vectorization is a methodology to map words or phrase from vocabulary to a corresponding vector of real numbers. These vectors can be used to find word similarities/semantics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 2. Loading Data</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:24.501227Z",
     "iopub.status.busy": "2021-10-10T14:30:24.500801Z",
     "iopub.status.idle": "2021-10-10T14:30:24.512257Z",
     "shell.execute_reply": "2021-10-10T14:30:24.511431Z",
     "shell.execute_reply.started": "2021-10-10T14:30:24.501190Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/amazon-fine-food-reviews'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c3665e9ad245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/amazon-fine-food-reviews'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/amazon-fine-food-reviews'"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../input/amazon-fine-food-reviews'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing the directories inside the input folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:24.513945Z",
     "iopub.status.busy": "2021-10-10T14:30:24.513519Z",
     "iopub.status.idle": "2021-10-10T14:30:27.789420Z",
     "shell.execute_reply": "2021-10-10T14:30:27.788623Z",
     "shell.execute_reply.started": "2021-10-10T14:30:24.513910Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv('../input/amazon-fine-food-reviews/Reviews.csv', delimiter=',')\n",
    "df1.dataframeName = 'Reviews.csv'\n",
    "nRow, nCol = df1.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Delimeter:</b> This is used to seperate data based on symbol given. The default value is comma. instead of delimiter parameter we can use \"sep\" parameter. \n",
    "\n",
    "df.shape gives us No of rows and no of columns present in the dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 3. Data Cleaning </h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:27.791655Z",
     "iopub.status.busy": "2021-10-10T14:30:27.791363Z",
     "iopub.status.idle": "2021-10-10T14:30:28.097278Z",
     "shell.execute_reply": "2021-10-10T14:30:28.096561Z",
     "shell.execute_reply.started": "2021-10-10T14:30:27.791616Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df1\n",
    "df.isna().sum().to_frame(name='# of missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text: Actual Text entered by the user. \n",
    "\n",
    "Summary: Short description about what the user feels \n",
    "\n",
    "Score: Worthiness that user feels about the product in range between 1 to 5 \n",
    "\n",
    "is_na() : checking the null values in the frame \n",
    "\n",
    "to_frame gives us the number of missing values in series \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:28.098985Z",
     "iopub.status.busy": "2021-10-10T14:30:28.098600Z",
     "iopub.status.idle": "2021-10-10T14:30:28.482296Z",
     "shell.execute_reply": "2021-10-10T14:30:28.481521Z",
     "shell.execute_reply.started": "2021-10-10T14:30:28.098944Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df1\n",
    "total_rows = df.shape[0]\n",
    "df.dropna(how='any',inplace=True)\n",
    "remaining_rows = df.shape[0]\n",
    "removed_rows = total_rows-remaining_rows\n",
    "print(total_rows)\n",
    "print(f\"Remaining rows are : { remaining_rows,np.round((remaining_rows/total_rows)*100,2)}%\") \n",
    "#F before string  = pythons way to tell that it is an python embeded expressions (like format specifier in c )\n",
    "print(f\"Removed rows {removed_rows,np.round((removed_rows/total_rows)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Storing the row count in \"total_row \"\n",
    "- Droping null values , inplace = True (making changes parmanent)\n",
    "- Storing the row count again after removing some null values in \"remaining_rows\"\n",
    "- Getting total row removed by subtracting total_Rows and remaining rows\n",
    "\n",
    "- Printing thoes values in with the help of format specifier command in string. \n",
    "- np.round() = gives rounding number.(value, no_of_roundings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:28.485514Z",
     "iopub.status.busy": "2021-10-10T14:30:28.484811Z",
     "iopub.status.idle": "2021-10-10T14:30:29.176787Z",
     "shell.execute_reply": "2021-10-10T14:30:29.176005Z",
     "shell.execute_reply.started": "2021-10-10T14:30:28.485476Z"
    }
   },
   "outputs": [],
   "source": [
    "# removind duplicate values \n",
    "before_duplicates = df.shape[0]\n",
    "df.drop_duplicates(inplace=True,subset=['Score','Text'])\n",
    "after_duplicate = df.shape[0]\n",
    "remaining_datas = before_duplicates-after_duplicate\n",
    "\n",
    "print(f\"Value before duplicate :: {np.round((before_duplicates/total_rows)*100,2)}%\")\n",
    "print(f\"Value after removing duplicate :: {np.round((after_duplicate/total_rows)*100)}%\")\n",
    "\n",
    "print(f\"Total duplicates removed :: {np.round((remaining_datas/total_rows)*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Storing the row count in \"before_duplicate \"\n",
    "- Droping duplicate values , inplace = True (making changes parmanent)\n",
    "- Storing the row count again after removing some null values in \"after_duplicate\"\n",
    "- Getting total row removed by subtracting before_duplicate and after_duplicate\n",
    "\n",
    "- Printing thoes values in with the help of format specifier command in string. \n",
    "- np.round() = gives rounding number.(value, no_of_roundings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:29.178653Z",
     "iopub.status.busy": "2021-10-10T14:30:29.178217Z",
     "iopub.status.idle": "2021-10-10T14:30:29.308455Z",
     "shell.execute_reply": "2021-10-10T14:30:29.307721Z",
     "shell.execute_reply.started": "2021-10-10T14:30:29.178617Z"
    }
   },
   "outputs": [],
   "source": [
    "c_b_r= df.shape[0] #count_before_relevant\n",
    "non_useful_idx = df[df['HelpfulnessNumerator']!=df['HelpfulnessDenominator']].index\n",
    "df.drop(index=non_useful_idx,inplace=True)\n",
    "c_a_r = df.shape[0] # count_after_relevant \n",
    "\n",
    "print(f\"Conunt before droping irilivent data :: { np.round((c_b_r/total_rows)*100,2)}%\")\n",
    "print(f\"Conunt after droping irilivent data :: { np.round((c_a_r/total_rows)*100,2)}%\")\n",
    "\n",
    "print(f\"Total no of rows removed :: {c_b_r-c_a_r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are droping the values which were not much helpful. Helpfulness was given in the dataset itself so we utilize thoes attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:29.310660Z",
     "iopub.status.busy": "2021-10-10T14:30:29.310007Z",
     "iopub.status.idle": "2021-10-10T14:30:29.393278Z",
     "shell.execute_reply": "2021-10-10T14:30:29.392623Z",
     "shell.execute_reply.started": "2021-10-10T14:30:29.310624Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_target(x):\n",
    "    return \"Positive\" if x>3 else \"Negative\" if x<3 else \"Neutral\"\n",
    "\n",
    "df['target'] = df.Score.apply(make_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are adding a column where values less then 3 becomes <b>Negative</b>, value equal to 3 becomes <b>Neutral</b> and Values greater then 3 become <b>Positive</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "4. Handle Imbalance Data </h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:29.394636Z",
     "iopub.status.busy": "2021-10-10T14:30:29.394370Z",
     "iopub.status.idle": "2021-10-10T14:30:29.636313Z",
     "shell.execute_reply": "2021-10-10T14:30:29.635557Z",
     "shell.execute_reply.started": "2021-10-10T14:30:29.394599Z"
    }
   },
   "outputs": [],
   "source": [
    "color = sns.color_palette \n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "tvc = df.target.value_counts()\n",
    "tvc.plot.barh(color='orange',fontsize=14,ax=ax)\n",
    "ax.set_title(\"Label vs Count\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sns.color_palette : Give us the multiple colors or color cycle\n",
    "\n",
    "- plt.subplots : (no of row, no column, count of colum)\n",
    "\n",
    "- df.target.value_count() : gives the total count of  each entity of target column\n",
    "\n",
    "- tvc.plot.barh() : gives us horizontal bargraph \n",
    "\n",
    "- fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "- ax = axes objects (1,2) means 1 row containing two plots \n",
    "\n",
    "- fig = instance of figure\n",
    "\n",
    "pyplot. subplots() returns a figure instance and an object or an array of Axes objects. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:29.638155Z",
     "iopub.status.busy": "2021-10-10T14:30:29.637406Z",
     "iopub.status.idle": "2021-10-10T14:30:30.004262Z",
     "shell.execute_reply": "2021-10-10T14:30:30.003494Z",
     "shell.execute_reply.started": "2021-10-10T14:30:29.638117Z"
    }
   },
   "outputs": [],
   "source": [
    "# downsampling: selecting certain number of sample  only\n",
    "df['target'].value_counts()\n",
    "neutral = df[df['target']==\"Neutral\"]\n",
    "positive = df[df['target']==\"Positive\"].sample(28000)\n",
    "negative = df[df['target']==\"Negative\"].sample(28000) \n",
    "\n",
    "df = pd.concat([neutral,positive,negative])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 4.1 Imbalanced Data  </h2>  \n",
    "A classification data set with skewed class porpotions is called imbalanced dataset. \n",
    "- Majority class : Classes that make large porpotoin of the data \n",
    "- Minority classes : Classes that make small porpotion of the data \n",
    "\n",
    "As we can see the imbalanced data. We address this problem with the following technique. \n",
    "\n",
    "### Downsampling \n",
    "- Reducing the quantity of majority classes so that it comes in range with minority classes \n",
    "\n",
    "### Upweighting \n",
    "- adding an example weight to the downsampled class equal to the factor we reduced\n",
    "\n",
    "\n",
    "Here we just downsampled. Explained in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.005852Z",
     "iopub.status.busy": "2021-10-10T14:30:30.005487Z",
     "iopub.status.idle": "2021-10-10T14:30:30.209097Z",
     "shell.execute_reply": "2021-10-10T14:30:30.208412Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.005808Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "tvc = df['target'].value_counts()\n",
    "\n",
    "tvc.plot.barh(color='orange',fontsize='14',ax=ax)\n",
    "\n",
    "ax.set_title(\"Label and Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity of each classes after down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.210666Z",
     "iopub.status.busy": "2021-10-10T14:30:30.210381Z",
     "iopub.status.idle": "2021-10-10T14:30:30.217094Z",
     "shell.execute_reply": "2021-10-10T14:30:30.216123Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.210629Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "py.init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.219323Z",
     "iopub.status.busy": "2021-10-10T14:30:30.218689Z",
     "iopub.status.idle": "2021-10-10T14:30:30.718774Z",
     "shell.execute_reply": "2021-10-10T14:30:30.717997Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.219267Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x = \"Score\")\n",
    "fig.update_traces(marker_color = \"turquoise\",marker_line_color='rgb(8,48,107)',marker_line_width = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 5. Pre Processing </h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.720522Z",
     "iopub.status.busy": "2021-10-10T14:30:30.720146Z",
     "iopub.status.idle": "2021-10-10T14:30:30.734447Z",
     "shell.execute_reply": "2021-10-10T14:30:30.733806Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.720482Z"
    }
   },
   "outputs": [],
   "source": [
    "total_stopwords = set(stopwords.words('english'))\n",
    "total_stopwords.update([\"br\",\"href\"])\n",
    "\n",
    "negative_stopwords = set(word for word in total_stopwords\n",
    "                        if \"n't\" in word or \"no\" in word)\n",
    "\n",
    "final_stopwords = total_stopwords - negative_stopwords\n",
    "final_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Negative words **\n",
    "\n",
    "As we not -ve words play vital role to determine -ve emotions or review so we removed them from stopwords \n",
    "\n",
    "**Stopwords.update **\n",
    "\n",
    "Allows us to update the existing the stopwords and add new stop words to the data. here we are adding\n",
    "br and href because this data dont make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.736096Z",
     "iopub.status.busy": "2021-10-10T14:30:30.735585Z",
     "iopub.status.idle": "2021-10-10T14:30:30.739812Z",
     "shell.execute_reply": "2021-10-10T14:30:30.739195Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.736044Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.741908Z",
     "iopub.status.busy": "2021-10-10T14:30:30.741115Z",
     "iopub.status.idle": "2021-10-10T14:30:30.749160Z",
     "shell.execute_reply": "2021-10-10T14:30:30.748331Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.741853Z"
    }
   },
   "outputs": [],
   "source": [
    "HTMLTAGS = re.compile('<.*?>')\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "remove_digits = str.maketrans('','',string.digits)\n",
    "MULTIPLE_WHITESPACE = re.compile(r\"\\s+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "5.1 re.compile  </h2> \n",
    "re.compile('<.* ?>') : getting all the html tags with the help of regular expression \n",
    "\n",
    "- The '*', '+', and '?' qualifiers are all greedy; they match as much text as possible. \n",
    "\n",
    "- Adding ? after the qualifier makes it perform the match in non-greedy or minimal fashion\n",
    "\n",
    "- <.*?>  will match only \"< a >\" if ? not given then whole string inside that tage will be matched \n",
    "\n",
    "####  string.punctuations\n",
    "  - return all the set of punctuations \n",
    "  \n",
    "#### dict.fromkeys(key, values)\n",
    "- makes keys for each possible value\n",
    "\n",
    "#### str.maketrance \n",
    "- makes unicode representation of each character of translation \n",
    "- In simple terms, maketrans() method is a static method that creates a one to one mapping of a character to its translation/replacement.\n",
    "\n",
    "- This translation mapping is then used for replacing a character to its mapped character when used in translate() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.751237Z",
     "iopub.status.busy": "2021-10-10T14:30:30.750389Z",
     "iopub.status.idle": "2021-10-10T14:30:30.759622Z",
     "shell.execute_reply": "2021-10-10T14:30:30.758802Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.751203Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_processer(review):\n",
    "    #remove html tags\n",
    "    review = HTMLTAGS.sub(r'',review)\n",
    "    \n",
    "    # removing puntuations \n",
    "    review = review.translate(table)\n",
    "    \n",
    "    # remove digits \n",
    "    review = review.translate(remove_digits)\n",
    "    \n",
    "    #lower case all letters \n",
    "    review = review.lower()\n",
    "    \n",
    "    #replace multiple white space with single space\n",
    "    review = MULTIPLE_WHITESPACE.sub(\" \",review).strip()\n",
    "    \n",
    "    \n",
    "    #remove stopwords\n",
    "    \n",
    "    review = [word for word in review.split()\n",
    "             if word not in final_stopwords]\n",
    "   #stemming \n",
    "\n",
    "    review = ' '.join([stemmer.stem(word) for word in review])\n",
    "    \n",
    "    return review \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Here, we have made a function that does the preprocssing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing values before pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.765320Z",
     "iopub.status.busy": "2021-10-10T14:30:30.764348Z",
     "iopub.status.idle": "2021-10-10T14:30:30.771258Z",
     "shell.execute_reply": "2021-10-10T14:30:30.770479Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.765286Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing values after preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:30:30.773243Z",
     "iopub.status.busy": "2021-10-10T14:30:30.772565Z",
     "iopub.status.idle": "2021-10-10T14:32:02.913665Z",
     "shell.execute_reply": "2021-10-10T14:32:02.912982Z",
     "shell.execute_reply.started": "2021-10-10T14:30:30.773208Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Text = df.Text.apply(pre_processer)\n",
    "df.Text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Selecting every text and adding them in variable textOnly\n",
    "\n",
    "2. generating wordcloud with the help of WordCloud function and inside that function calling generate() function  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 6. Visualize with Word Cloud</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " <b> 6.1 Positive words </b></h2> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:02.915466Z",
     "iopub.status.busy": "2021-10-10T14:32:02.915209Z",
     "iopub.status.idle": "2021-10-10T14:32:02.921122Z",
     "shell.execute_reply": "2021-10-10T14:32:02.920107Z",
     "shell.execute_reply.started": "2021-10-10T14:32:02.915432Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_clouds(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    \n",
    "    wordcloud = WordCloud(stopwords=stopwords,background_color=\"white\")\n",
    "    wordcloud.generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(wordcloud,interpolation='bilinear')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:02.922861Z",
     "iopub.status.busy": "2021-10-10T14:32:02.922554Z",
     "iopub.status.idle": "2021-10-10T14:32:11.085059Z",
     "shell.execute_reply": "2021-10-10T14:32:11.084382Z",
     "shell.execute_reply.started": "2021-10-10T14:32:02.922827Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = df[df['target']=='Positive'].Text\n",
    "pos_text = \" \".join(review for review in pos.astype(str))\n",
    "generate_clouds(pos_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " <b>6.2 Negative words </b></h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:11.086562Z",
     "iopub.status.busy": "2021-10-10T14:32:11.086236Z",
     "iopub.status.idle": "2021-10-10T14:32:19.985536Z",
     "shell.execute_reply": "2021-10-10T14:32:19.984767Z",
     "shell.execute_reply.started": "2021-10-10T14:32:11.086525Z"
    }
   },
   "outputs": [],
   "source": [
    "neg = df[df['target']==\"Negative\"].Text\n",
    "\n",
    "neg_text =\" \".join(review for review in neg.astype(str))\n",
    "generate_clouds(neg_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " <b>6.3 Neutral words </b></h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:19.987184Z",
     "iopub.status.busy": "2021-10-10T14:32:19.986833Z",
     "iopub.status.idle": "2021-10-10T14:32:28.045577Z",
     "shell.execute_reply": "2021-10-10T14:32:28.044798Z",
     "shell.execute_reply.started": "2021-10-10T14:32:19.987147Z"
    }
   },
   "outputs": [],
   "source": [
    "neut = df[df['target']==\"Neutral\"].Text\n",
    "\n",
    "neut_text =\" \".join(review for review in neut.astype(str))\n",
    "generate_clouds(neut_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting Our final data in train and test set. \n",
    "\n",
    "Detailed Document is with visual representation is given in word format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 7. Train Test Split</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:28.047222Z",
     "iopub.status.busy": "2021-10-10T14:32:28.046974Z",
     "iopub.status.idle": "2021-10-10T14:32:28.194783Z",
     "shell.execute_reply": "2021-10-10T14:32:28.194027Z",
     "shell.execute_reply.started": "2021-10-10T14:32:28.047190Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X=df.Text\n",
    "y= df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing total rows for test and train sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:28.199497Z",
     "iopub.status.busy": "2021-10-10T14:32:28.199254Z",
     "iopub.status.idle": "2021-10-10T14:32:28.204706Z",
     "shell.execute_reply": "2021-10-10T14:32:28.204062Z",
     "shell.execute_reply.started": "2021-10-10T14:32:28.199472Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 8. WordWord Vectorization </h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " <b>8.1 Transform </b></h2> \n",
    " \n",
    " ### Fit \n",
    " \n",
    "Computes the mean and standard deviatoin if the feature \n",
    "\n",
    "\n",
    "To apply changes from the fit method to the data \n",
    "\n",
    "#### Fit_Transform \n",
    "This is the combination both the methods fit and transform. Equivilent to fit().transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:28.206403Z",
     "iopub.status.busy": "2021-10-10T14:32:28.205814Z",
     "iopub.status.idle": "2021-10-10T14:32:34.780800Z",
     "shell.execute_reply": "2021-10-10T14:32:34.779944Z",
     "shell.execute_reply.started": "2021-10-10T14:32:28.206365Z"
    }
   },
   "outputs": [],
   "source": [
    "bow_vectorizor = CountVectorizer()\n",
    "bow_vectorizor.fit(X_train)\n",
    "\n",
    "\n",
    "X_train_bow = bow_vectorizor.transform(X_train)\n",
    "X_test_bow = bow_vectorizor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " <b>8.2 Count Vectorizer  </b></h2> \n",
    "It is the method of converting text data into vector.\n",
    "\n",
    "First when we are fitting every text that is given a unique number one time even that item might repeat itself. ex(ram :1 , ram:1 , ram:1). the text ram will always have vector value as 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:34.782341Z",
     "iopub.status.busy": "2021-10-10T14:32:34.782090Z",
     "iopub.status.idle": "2021-10-10T14:32:41.238172Z",
     "shell.execute_reply": "2021-10-10T14:32:41.237452Z",
     "shell.execute_reply.started": "2021-10-10T14:32:34.782308Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "  8.3 TF-IDF (Trem frequeny - Inverse Term frequency)</h2> \n",
    "\n",
    "TF-IDF converts the word into vector where as it assign repeated words in every document's as low value. Thre more repeated that certain value is more likley it is that it will be towards 0. Doing this makes removes the values that dont contribute much in the feature extraction process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style = \"font-size:15px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "  8.4 Label Encoding </h2> \n",
    "Label Encoding is the process of giving uniqe number to any item so that it can be properly labeld or identified. Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:41.239990Z",
     "iopub.status.busy": "2021-10-10T14:32:41.239718Z",
     "iopub.status.idle": "2021-10-10T14:32:41.270221Z",
     "shell.execute_reply": "2021-10-10T14:32:41.269355Z",
     "shell.execute_reply.started": "2021-10-10T14:32:41.239957Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "y_train = labelEncoder.fit_transform(y_train)\n",
    "y_test = labelEncoder.fit_transform(y_test)\n",
    "\n",
    "labels = labelEncoder.classes_.tolist() ###\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to evaluate our data with the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 9. Model Creation </h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:41.271886Z",
     "iopub.status.busy": "2021-10-10T14:32:41.271455Z",
     "iopub.status.idle": "2021-10-10T14:32:41.279046Z",
     "shell.execute_reply": "2021-10-10T14:32:41.278084Z",
     "shell.execute_reply.started": "2021-10-10T14:32:41.271836Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model,trainX,trainY,testX,testY):\n",
    "    model.fit(trainX,trainY)\n",
    "    \n",
    "    pred_by_train = model.predict(trainX)\n",
    "    pred_by_test = model.predict(testX)\n",
    "    \n",
    "    print(\"Evaluation\")\n",
    "    \n",
    "    print(f\"Accuracy on Train {accuracy_score(trainY,pred_by_train)}\")\n",
    "    print(f\"Accuracy on Test {accuracy_score(testY,pred_by_test)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "    9.1 Logistic regression Model</h2> \n",
    "<br>\n",
    "\n",
    "###  hyperparameter optimization \n",
    "This  is the process of chosing best fited parameters. Here we are doing hyper parameter tunning. by changing the c values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T14:32:41.280596Z",
     "iopub.status.busy": "2021-10-10T14:32:41.280236Z"
    }
   },
   "outputs": [],
   "source": [
    "C = [0.001, 0.01, 0.1]\n",
    "\n",
    "for c in C:\n",
    "    log_model = LogisticRegression(C=c, max_iter=500, random_state=1)\n",
    "    \n",
    "    train_and_evaluate(model=log_model,\n",
    "                      trainX=X_train_bow,\n",
    "                      trainY=y_train,\n",
    "                      testX=X_test_bow,\n",
    "                      testY=y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 9.2 Naive Bayes Model</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0,0.2,0.6,0.8,1]\n",
    "\n",
    "for a in alpha:\n",
    "    nb_model = MultinomialNB(alpha=a)\n",
    "    train_and_evaluate(model=nb_model,\n",
    "                       trainX=X_train_tfidf,\n",
    "                      trainY=y_train,\n",
    "                      testX=X_test_tfidf,\n",
    "                      testY=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "9.3 Confusion Matrix</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(y_true,y_pred):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    cm= confusion_matrix(y_true,y_pred,normalize='true')\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cm, annot=True, cmap='Blues', cbar=False, fmt='.2f',\n",
    "        xticklabels=labels, yticklabels=labels)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    " 9.4 Best Model</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model \n",
    "\n",
    "bmodel=LogisticRegression(C=1,max_iter=500,random_state=1)\n",
    "bmodel.fit(X_train_tfidf,y_train)\n",
    "y_pred_train = bmodel.predict(X_train_tfidf)\n",
    "y_pred_test = bmodel.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:25px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "10. Save Model</h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transformer.pkl\",\"wb\") as f:\n",
    "    pickle.dump(tfidf_vectorizer,f)\n",
    "\n",
    "with open(\"model.pkl\",\"wb\") as f:\n",
    "    pickle.dump(bmodel,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h2 style = \"font-size:20px;\n",
    "             font-family:serif;\n",
    "             font-weight : bold;\n",
    "             background-color:#5d6d7e;\n",
    "             color : #f4d03f ;\n",
    "             text-align: center;\n",
    "             border-radius: 5px 5px;\n",
    "             padding: 5px\">\n",
    "10.1 Prediction </h2> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(review):\n",
    "    \n",
    "    x = pre_processer(review)\n",
    "    \n",
    "    x = tfidf_vectorizer.transform([x])\n",
    "    \n",
    "    y = int(bmodel.predict(x.reshape(1,-1)))\n",
    "    \n",
    "    return labels[y]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"This was Over all item was nice\"\n",
    "\n",
    "print(f\"This is a {get_sentiment(review)} review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
